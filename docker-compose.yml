version: '3.5'
services:
  scrapper:
    container_name: service-scrapper
    build:
      context: .
      dockerfile: app.scrapper.Dockerfile
    environment:
      - RABBIT_EXCHANGE_NAME
      - RABBIT_FQDN
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'
    deploy:
      resources:
        limits:
          cpus: 1
          memory: 512m
    depends_on:
      elasticsearch:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
  backend:
    container_name: service-backend
    build:
      context: .
      dockerfile: app.backend.Dockerfile
    environment:
      - TELEGRAM_BOT_TOKEN
      - ELASTICSEARCH_INDEX
      - ELASTICSEARCH_HOST
      - RABBIT_EXCHANGE_NAME
      - RABBIT_FQDN
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'
    deploy:
      resources:
        limits:
          cpus: 0.5
          memory: 100m
    depends_on:
      elasticsearch:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
  notifier:
    container_name: service-notifier
    build:
      context: .
      dockerfile: app.notifier.Dockerfile
    environment:
      - TWITTER_API_KEY
      - TWITTER_API_KEY_SECRET
      - TWITTER_ACCESS_TOKEN
      - TWITTER_ACCESS_TOKEN_SECRET
      - TELEGRAM_BOT_TOKEN
      - TELEGRAM_CHANNEL_ID
      - TELEGRAM_ADMIN_CHANNEL_ID
      - RABBIT_EXCHANGE_NAME
      - RABBIT_FQDN
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'
    deploy:
      resources:
        limits:
          cpus: 0.5
          memory: 100m
    depends_on:
      elasticsearch:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
  elasticsearch:
    container_name: infra-elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0
    environment:
      - xpack.security.enabled=false
      - discovery.type=single-node
    volumes:
      - ./docker/elasticsearch:/usr/share/elasticsearch/data
    ulimits:
      memlock:
        soft: -1
        hard: -1
    restart: unless-stopped
    ports:
      - 9200:9200
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'
    deploy:
      resources:
        limits:
          cpus: 1
          memory: 512m
    healthcheck:
      test: curl -u elastic:elastic -s -f elasticsearch:9200/_cat/health >/dev/null || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
  kibana:
    container_name: infra-kibana
    image: docker.elastic.co/kibana/kibana:7.15.0
    environment:
      SERVER_NAME: localhost
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports:
      - 5601:5601
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'
    deploy:
      resources:
        limits:
          cpus: 1
          memory: 512m
    restart: unless-stopped
    depends_on:
      elasticsearch:
        condition: service_healthy
  rabbitmq:
    container_name: infra-rabbitmq
    image: rabbitmq:3-management-alpine
    volumes:
      - ./docker/rabbitmq:/var/lib/rabbitmq
    environment:
      RABBITMQ_ERLANG_COOKIE: ThisIsACookie
      RABBITMQ_DEFAULT_USER: retail
      RABBITMQ_DEFAULT_PASS: retail
    ports:
      - 5672:5672
      - 15672:15672
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: '10m'
        max-file: '3'
    deploy:
      resources:
        limits:
          cpus: 0.5
          memory: 256m
    healthcheck:
      test: rabbitmq-diagnostics -q ping
      interval: 10s
      timeout: 5s
      retries: 5
